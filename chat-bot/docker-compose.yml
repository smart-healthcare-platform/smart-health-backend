# Docker Compose file for the Smart Health Chatbot
# Version: 3.9

# --- IMPORTANT ---
# Before starting, you must pull the required Ollama model manually.
# Run the following command in your terminal:
# docker exec -it ollama ollama pull llama3.2:latest
# -----------------

services:
  # Ollama service to run the local LLM
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11435:11434" # Expose on host port 11435 to avoid conflicts
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - chatbot-net

  # ChromaDB service for the vector store
  chromadb:
    image: chromadb/chroma:latest
    container_name: chromadb
    ports:
      - "8002:8000" # Expose on host port 8002 to avoid conflicts
    volumes:
      - chroma_data:/data # Persist ChromaDB data
    networks:
      - chatbot-net
    command: ["run", "--host", "0.0.0.0", "--port", "8000", "--path", "/data"]

  # Data ingestion service to populate ChromaDB
  ingestor:
    build: .
    container_name: chatbot_ingestor
    depends_on:
      chromadb:
        condition: service_started
    networks:
      - chatbot-net
    environment:
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
    # This command runs the ingestion script and then the container exits.
    command:
      [
        "python",
        "-c",
        "from src.rag_pipeline import ingest_data; ingest_data()",
      ]
    restart: "no" # Ensure it only runs once

  # Main application service
  app:
    build: .
    container_name: chatbot_app
    ports:
      - "8003:8000" # Expose on host port 8003 to avoid conflicts
    volumes:
      - ./src:/app/src
      - ./knowledge_base:/app/knowledge_base
    networks:
      - chatbot-net
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
    depends_on:
      ollama:
        condition: service_started
      chromadb:
        condition: service_started
      ingestor:
        condition: service_completed_successfully
    restart: unless-stopped

volumes:
  ollama_data:
    driver: local
  chroma_data:
    driver: local

networks:
  chatbot-net:
    driver: bridge
